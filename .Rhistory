# Load the National Park data from the following URL
# https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv
# Save as np_data
np_data <- read.csv("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv ")
# Load the National Park data from the following URL
# https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv
# Save as np_data
np_data <- read.csv("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv")
# Find the average number of visits for each National Park
# Save as avg_park_visits and View()
# What park has the most and least average visits?
# What patterns or surprises do you notice?
avg_state_visits <- np_data %>%
group_by(State) %>%
summarize(avg_visits = mean(RecreationVisits))
# Install tidyverse
# install.packages("tidyverse")
# Load dplyr
library(dplyr)
# Add a new column "park_state" to the dataframe that combines the name of each National Park and the state in which it is located like so
# Olympic NP, WA
Your code here
# Load the data from the following URL
# https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv
# Save as np_data
np_data <- read.csv("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv", stringsAsFactors = FALSE)
# Add a new column "park_state" to the dataframe that combines the name of each National Park and the state in which it is located like so
# Olympic NP, WA
Your code here
# Load the National Park data from the following URL
# https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv
# Save as np_data
np_data <- read.csv("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv")
# Find the average number of visits for each National Park
# Save as avg_park_visits and View()
# What park has the most and least average visits?
# What patterns or surprises do you notice?
avg_state_visits <- np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits))
view(avg_state_visits)
# Find the average number of visits for each state
# Save as avg_state_visits and View()
# What state has the most and least average visits?
# What patterns or surprises do you notice?
avg_park_visits <- np_data %>%
group_by(State) %>%
summarize(avg_visits = mean(RecreationVisits))
# Load the National Park data from the following URL
# https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv
# Save as np_data
np_data <- read.csv("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv")
library(dplyr)
# Find the average number of visits for each National Park
# Save as avg_park_visits and View()
# What park has the most and least average visits?
# What patterns or surprises do you notice?
avg_state_visits <- np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits))
view(avg_state_visits)
# Find the average number of visits for each state
# Save as avg_state_visits and View()
# What state has the most and least average visits?
# What patterns or surprises do you notice?
avg_park_visits <- np_data %>%
group_by(State) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_park_visits)
# Find the average number of visits for each National Park AND state (group by two columns!)
# Save as avg_park__state_visits and View()
# What National Park has the most and least average visits?
# What patterns or surprises do you notice?
avg_park_visits <- np_data %>%
group_by(ParkName, State) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_park_visits)
view(avg_state_visits)
# Load the National Park data from the following URL
# https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv
# Save as np_data
np_data <- read.csv("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv")
library(dplyr)
# Find the average number of visits for each National Park
# Save as avg_park_visits and View()
# What park has the most and least average visits?
# What patterns or surprises do you notice?
avg_state_visits <- np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_state_visits)
avg_state_visits <- np_data %>%
group_by(State) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_state_visits)
# Find the average number of visits for each National Park AND state
# Save as avg_park_visits and View()
# What National Park has the most and least average visits?
# What patterns or surprises do you notice?
avg_park_visits <- np_data %>%
group_by(ParkName, State) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_park_visits)
# Find the average number of visits for each state
# Save as avg_state_visits and View()
# What state has the most and least average visits?
# What patterns or surprises do you notice?
avg_park_visits <- np_data %>%
group_by(State) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_park_visits)
# Find the average number of visits for each National Park AND state (group by two columns!)
# Save as avg_park__state_visits and View()
# What National Park has the most and least average visits?
# What patterns or surprises do you notice?
avg_park_visits <- np_data %>%
group_by(ParkName, State) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_park_visits)
# Find the number of distinct parks for each state
# Save as distinct_parks
# Which state has the most national parks?
# What patterns or surprises do you notice?
distinct_parks <- np_data %>%
group_by(State) %>%
summarize(distinct_parks = n_distinct(ParkName))
# What is the average number of visits for each National Park from 1979-2020?
# Save as avg_visits
# NOTE: You probably won't be able to answer this question without a new DPLYR concept, but make your best effort and try to identify what steps are missing
avg_visits <- np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits))
# Exploring visits to National Parks through data
library(dplyr)
# Load the data from the following URL
# https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv
# Save as np_data
np_data <- read.csv("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv", stringsAsFactors = FALSE)
# Add a new column "park_state" to the dataframe that combines the name of each National Park and the state in which it is located like so
# Olympic NP, WA
np_data <- np_data %>%
mutate(park_state = paste0(ParkName, ", ", State))
# What is the single greatest number of Recreation Visits for any National Park in any year?
# Save this filtered row as max_visits_row
max_visits_row <- np_data %>%
filter(RecreationVisits == max(RecreationVisits))
# Now "pull" only the max number of visits and save as max_visits
max_visits <- np_data %>%
filter(RecreationVisits == max(RecreationVisits)) %>% pull(RecreationVisits)
# What is the lowest number of Recreation Visits for any National Park in any year?
# Save this filtered row as min_visits_row
min_visits_row <- np_data %>%
filter(RecreationVisits == min(RecreationVisits))
# Now "pull" only the max number of visits and save as min_visits
min_visits <- np_data %>%
filter(RecreationVisits == min(RecreationVisits)) %>% pull(RecreationVisits)
# What is the average number of visits for each National Park from 1979-2020?
# Save as avg_visits
# NOTE: You probably won't be able to answer this question without a new DPLYR concept, but make your best effort and try to identify what steps are missing
avg_visits <- np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits))
# Exploring visits to National Parks through data
library(dplyr)
# Load the data from the following URL
# https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv
# Save as np_data
np_data <- read.csv("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv", stringsAsFactors = FALSE)
# Add a new column "park_state" to the dataframe that combines the name of each National Park and the state in which it is located like so
# Olympic NP, WA
np_data <- np_data %>%
mutate(park_state = paste0(ParkName, ", ", State))
# What is the single greatest number of Recreation Visits for any National Park in any year?
# Save this filtered row as max_visits_row
max_visits_row <- np_data %>%
filter(RecreationVisits == max(RecreationVisits))
# Now "pull" only the max number of visits and save as max_visits
max_visits <- np_data %>%
filter(RecreationVisits == max(RecreationVisits)) %>% pull(RecreationVisits)
# What is the lowest number of Recreation Visits for any National Park in any year?
# Save this filtered row as min_visits_row
min_visits_row <- np_data %>%
filter(RecreationVisits == min(RecreationVisits))
# Now "pull" only the max number of visits and save as min_visits
min_visits <- np_data %>%
filter(RecreationVisits == min(RecreationVisits)) %>% pull(RecreationVisits)
# What is the average number of visits for each National Park from 1979-2020?
# Save as avg_visits
# NOTE: You probably won't be able to answer this question without a new DPLYR concept, but make your best effort and try to identify what steps are missing
avg_visits <- np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_visits)
View(avg_visits)
View(max_visits_row)
View(max_visits_row)
View(min_visits_row)
View(min_visits_row)
View(np_data)
View(min_visits_row)
# Exploring visits to National Parks through data
library(dplyr)
# Load the data from the following URL
# https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv
# Save as np_data
np_data <- read.csv("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv", stringsAsFactors = FALSE)
# Add a new column "park_state" to the dataframe that combines the name of each National Park and the state in which it is located like so
# Olympic NP, WA
np_data <- np_data %>%
mutate(park_state = paste0(ParkName, ", ", State))
# What is the single greatest number of Recreation Visits for any National Park in any year?
# Save this filtered row as max_visits_row
max_visits_row <- np_data %>%
filter(RecreationVisits == max(RecreationVisits))
# Now "pull" only the max number of visits and save as max_visits
max_visits <- np_data %>%
filter(RecreationVisits == max(RecreationVisits)) %>%
pull(RecreationVisits)
# What is the lowest number of Recreation Visits for any National Park in any year?
# Save this filtered row as min_visits_row
min_visits_row <- np_data %>%
filter(RecreationVisits == min(RecreationVisits))
# Now "pull" only the max number of visits and save as min_visits
min_visits <- np_data %>%
filter(RecreationVisits == min(RecreationVisits)) %>%
pull(RecreationVisits)
# What is the average number of visits for each National Park from 1979-2020?
# Save as avg_visits
# NOTE: You probably won't be able to answer this question without a new DPLYR concept, but make your best effort and try to identify what steps are missing
avg_visits <- np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits))
# Load the National Park data from the following URL
# https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv
# Save as np_data
np_data <- read.csv("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv")
library(dplyr)
# Find the average number of visits for each National Park
# Save as avg_park_visits and View()
# What park has the most and least average visits?
# What patterns or surprises do you notice?
avg_state_visits <- np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_state_visits)
# Load the National Park data from the following URL
# https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv
# Save as np_data
np_data <- read.csv("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv")
library(dplyr)
# Find the average number of visits for each National Park
# Save as avg_park_visits and View()
# What park has the most and least average visits?
# What patterns or surprises do you notice?
avg_park_visits <- np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_park_visits)
View(avg_park_visits)
# Find the average number of visits for each state
# Save as avg_state_visits and View()
# What state has the most and least average visits?
# What patterns or surprises do you notice?
avg_state_visits <- np_data %>%
group_by(State) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_state_visits)
# Find the average number of visits for each National Park AND state (group by two columns!)
# Save as avg_park__state_visits and View()
# What National Park has the most and least average visits?
# What patterns or surprises do you notice?
avg_park__state_visits <- np_data %>%
group_by(ParkName, State) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_park__state_visits)
View(avg_park_visits)
View(avg_state_visits)
View(avg_park__state_visits)
# Find the number of distinct parks for each state
# Save as distinct_parks
# Which state has the most national parks?
# What patterns or surprises do you notice?
distinct_parks <- np_data %>%
group_by(State) %>%
summarize(distinct_parks = n_distinct(ParkName))
View(distinct_parks)
View(avg_park__state_visits)
View(avg_park_visits)
View(avg_state_visits)
View(distinct_parks)
# Load the National Park data from the following URL
# https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv
# Save as np_data
np_data <- read.csv("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv")
library(dplyr)
# Find the average number of visits for each National Park
# Save as avg_park_visits and View()
# What park has the most and least average visits?
# What patterns or surprises do you notice?
avg_park_visits <- np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_park_visits)
# Find the average number of visits for each state
# Save as avg_state_visits and View()
# What state has the most and least average visits?
# What patterns or surprises do you notice?
avg_state_visits <- np_data %>%
group_by(State) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_state_visits)
# Find the average number of visits for each National Park AND state (group by two columns!)
# Save as avg_park__state_visits and View()
# What National Park has the most and least average visits?
# What patterns or surprises do you notice?
avg_park__state_visits <- np_data %>%
group_by(ParkName, State) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_park__state_visits)
# Find the number of distinct parks for each state
# Save as distinct_parks
# Which state has the most national parks?
# What patterns or surprises do you notice?
distinct_parks <- np_data %>%
group_by(State) %>%
summarize(distinct_parks = n_distinct(ParkName))
# A: CA has the most national parks.
# A: CA has the most national parks.
# I found funny that AK has top 2 numbers of NP but its visits are not a lot.
# A: CA has the most national parks.
# I found funny that AK has top 2 numbers of NP but its visits are not a lot.
# Install package/data
install.packages("nycflights13")
# Load necessary libraries
library("nycflights13")
library("dplyr")
# Load dataframes
flights <- flights
airlines <- airlines
airports <- airports
# What was the average departure delay in each month?
# Save this as a data frame `dep_delay_by_month`
# Hint: you'll have to perform a grouping operation then summarize your data
dep_delay_by_month <- flights %>%
group_by(month) %>%
summarize(delay = mean(dep_delay, na.rm = TRUE))
# If your above data frame contains just two columns (e.g., "month", and "delay" in that order), you can create a scatterplot by passing that data frame to the built-in `plot()` function
plot(dep_delay_by_month, type = 'b')
# Use `left_join()` to join the "flights" dataframe to the "airlines" dataframe, which has the airline information
flights_airlines <- left_join(flights, airlines)
# What was the average departure delay for each airline?
# Hint: you'll have to perform a grouping operation then summarize your data
dep_delay_by_airline <- flights_airlines %>%
group_by(name) %>%
summarize(delay = mean(dep_delay, na.rm = TRUE))
# Load the data from the following URL
# https://github.com/melaniewalsh/Neat-Datasets/raw/main/Survivor-Viewers.csv
# Save as survivor_df
survivor_df <- read.csv("https://github.com/melaniewalsh/Neat-Datasets/raw/main/Survivor-Viewers.csv", stringsAsFactors = FALSE)
# Load the DPLYR library
library(dplyr)
# Calculate the average number of viewers for each season `avg_viewers`
season_avg_viewers <- survivor_df %>%
group_by(season) %>%
summarize(avg_viewers = mean(viewers, na.rm=TRUE))
# For fun, let's make a plot of avg viewers over season number
plot(season_avg_viewers, type='b')
# Find the episode with the most number of viewers `most_views_row`
most_views_row <- survivor_df %>%
filter(viewers == max(viewers, na.rm=TRUE)) %>%
pull(viewers)
# Find the episode with the most number of viewers, then pull the number of viewers and save it as a variable `most_views`
most_views <- survivor_df %>%
filter(viewers == max(viewers, na.rm=TRUE)) %>%
pull(viewers)
# Lele Zhang
# lelez@uw.edu
# I worked on this assignment alone using only this quarter's course materials
install.packages("tidyverse")
library(stringr)
#loads in the stringr library, all library statements must be at the top of the page!
library(dplyr)
# Note: You may have to run: install.packages("testthat")
library(testthat)
# Note: make sure to set your source-> working directory to current file location
games_df <- read.csv("2013_Video_Games_Dataset.csv") #loads in your dataset DO NOT CHANGE!!
# What percentage of games in the dataset are sequels? Round this number to the nearest whole number/integer
# and store into a variable called `perc_seq`
perc_seq <- round((total_seq / total_games) * 100)
????????????????????????????????????????????????????????
# We now want to figure out information about games that were published by AAA studios.
# The AAA studios are:  Activision, Nintendo, Rockstar, Sony, Disney, Electronic Arts, and Microsoft
# Below we provide you with a regular expression (regex) pattern to let you check if a text
# contains any of those studio names:
aaa_studios_pattern <- "Activision|Nintend|Rockstar|Sony|Disney|Electronic Arts|Microsoft"
# Open the games_df dataframe and copy text for one of the publishers, and put save it in
# a variable called `example_publisher_text`
example_publisher_text <- games_df$Publisher[1]
# Lele Zhang
# lelez@uw.edu
# I worked on this assignment alone using only this quarter's course materials
install.packages("tidyverse")
library(stringr)
#loads in the stringr library, all library statements must be at the top of the page!
library(dplyr)
# Note: You may have to run: install.packages("testthat")
library(testthat)
# Note: make sure to set your source-> working directory to current file location
games_df <- read.csv("2013_Video_Games_Dataset.csv") #loads in your dataset DO NOT CHANGE!!
# How many games in total are in this dataset? Store this value into a variable called `total_games`
total_games <- nrow(games_df)
print(total_games)
# Make a new dataframe called `sequel_games_df` with just the games that are sequels
sequel_games_df <- games_df %>% filter(Sequel == 1)
# Lele Zhang
# lelez@uw.edu
# I worked on this assignment alone using only this quarter's course materials
install.packages("tidyverse")
library(stringr)
#loads in the stringr library, all library statements must be at the top of the page!
library(dplyr)
# Note: You may have to run: install.packages("testthat")
library(testthat)
# Note: make sure to set your source-> working directory to current file location
games_df <- read.csv("2013_Video_Games_Dataset.csv") #loads in your dataset DO NOT CHANGE!!
# Note: make sure to set your source-> working directory to current file location
games_df <- read.csv("2013_Video_Games_Dataset.csv") #loads in your dataset DO NOT CHANGE!!
# How many games in total are in this dataset? Store this value into a variable called `total_games`
total_games <- nrow(games_df)
print(total_games)
# Calculate the standard deviation of game sales
# Hint: you can Google for the R function to find the standard deviation
# Store this value into a variable named `std_dev_sales`
std_dev_sales <- sd(games_df$US.Sales..millions., na.rm = TRUE)
print(std_dev_sales)
#loads in the stringr library, all library statements must be at the top of the page!
library(stringr)
library(dplyr)
# Note: You may have to run: install.packages("testthat")
library(testthat)
# Note: make sure to set your source-> working directory to current file location
games_df <- read.csv("2013_Video_Games_Dataset.csv") #loads in your dataset DO NOT CHANGE!!
# How many games in total are in this dataset? Store this value into a variable called `total_games`
total_games <- nrow(games_df)
print(total_games)
# Make a new dataframe called `sequel_games_df` with just the games that are sequels
sequel_games_df <- games_df %>% filter(Sequel != 0)
#loads in the stringr library, all library statements must be at the top of the page!
library(stringr)
library(dplyr)
# Note: You may have to run: install.packages("testthat")
library(testthat)
# Note: make sure to set your source-> working directory to current file location
games_df <- read.csv("2013_Video_Games_Dataset.csv") #loads in your dataset DO NOT CHANGE!!
# How many games in total are in this dataset? Store this value into a variable called `total_games`
total_games <- nrow(games_df)
print(total_games)
#loads in the stringr library, all library statements must be at the top of the page!
library(stringr)
library(dplyr)
# Note: You may have to run: install.packages("testthat")
library(testthat)
# Note: make sure to set your source-> working directory to current file location
games_df <- read.csv("2013_Video_Games_Dataset.csv") #loads in your dataset DO NOT CHANGE!!
#loads in the stringr library, all library statements must be at the top of the page!
library(stringr)
library(dplyr)
# Note: You may have to run: install.packages("testthat")
library(testthat)
# Note: make sure to set your source-> working directory to current file location
games_df <- read.csv("2013_Video_Games_Dataset.csv") #loads in your dataset DO NOT CHANGE!!
# Note: make sure to set your source-> working directory to current file location
games_df <- read.csv("2013_Video_Games_Dataset.csv") #loads in your dataset DO NOT CHANGE!!
# How many games in total are in this dataset? Store this value into a variable called `total_games`
total_games <- nrow(games_df)
print(total_games)
# Make a new dataframe called `sequel_games_df` with just the games that are sequels
sequel_games_df <- games_df %>% filter(Sequel != 0)
#loads in the stringr library, all library statements must be at the top of the page!
library(stringr)
library(dplyr)
# Note: You may have to run: install.packages("testthat")
library(testthat)
# Note: make sure to set your source-> working directory to current file location
games_df <- read.csv("2013_Video_Games_Dataset.csv") #loads in your dataset DO NOT CHANGE!!
# How many games in total are in this dataset? Store this value into a variable called `total_games`
total_games <- nrow(games_df)
print(total_games)
# Make a new dataframe called `sequel_games_df` with just the games that are sequels
sequel_games_df <- games_df %>% filter(Sequel != 0)
source("~/Downloads/INFO 201/HW/hw2_games/Lele Zhang - hw2.r")
install.packages('rsconnect')
install.packages("rsconnect")
library(rsconnect)
rsconnect::deployApp('path/to/your/app')
shiny::runApp('Documents/Info_201_Final_Project')
combined_df <- read.csv("Comprehensive Physical Health and Occupational Statistics Dataset.csv")
runApp('Documents/Info_201_Final_Project')
combined_df <- read.csv("Comprehensive Physical Health and Occupational Statistics Dataset.csv")
setwd("~/Documents/Info_201_Final_Project")
combined_df <- read.csv("Comprehensive Physical Health and Occupational Statistics Dataset.csv")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
