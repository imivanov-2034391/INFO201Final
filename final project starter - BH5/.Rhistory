proportion_b_w_m <- w_avg_front / m_avg_front
w_avg_front / m_avg_front
w_avg_back <- women_pockets %>%
summarize(mean(maxHeightBack))
m_avg_back <- men_pockets %>%
summarize(mean(maxHeightBack))
proportion_b_w_m_f <- w_avg_front / m_avg_front
proportion_b_w_m_b <- w_avg_front / m_avg_front
proportion_b_w_m_f <- w_avg_front / m_avg_front
proportion_b_w_m_b <- w_avg_back / m_avg_back
w_avg_back / m_avg_back
library("dplyr")
holfstede_df <- read.csv(
"https://geerthofstede.com/wp-content/uploads/2016/08/6-dimensions-for-website-2015-08-16.csv",
sep = ";" #the file isn't separated by commas, but instead semi-colons
)
hofstede_df <- read.csv(
"https://geerthofstede.com/wp-content/uploads/2016/08/6-dimensions-for-website-2015-08-16.csv",
sep = ";" #the file isn't separated by commas, but instead semi-colons
)
us_idv <- hofstede_df %>%
filter(ctr == "USA") %>%
pull(idv)
china_idv <- hofstede_df %>%
filter(ctr == "CHI") %>%
pull(idv)
avg_idv <- hofstede_df %>%
summarize(adv_idv = mean(idv))
avg_idv <- hofstede_df %>%
summarize(adv_idv = mean(idv, na.rm = TRUE))
avg_idv <- hofstede_df %>%
filter(is.numeric(idv))
summarize(adv_idv = mean(idv, na.rm = TRUE))
avg_idv <- hofstede_df %>%
mutate(idv_num = as.numeric(idv))
avg_idv <- hofstede_df %>%
mutate(idv_num = as.numeric(idv)) %>%
summarize(adv_idv = mean(idv, na.rm = TRUE))
avg_idv <- hofstede_df %>%
mutate(idv_num = as.numeric(idv)) %>%
summarize(adv_idv = mean(idv_num, na.rm = TRUE))
avg_idv <- hofstede_df %>%
mutate(idv_num = as.numeric(idv)) %>%
summarize(avg_idv = mean(idv_num, na.rm = TRUE)) %>%
pull(avg_idv)
us_idv <- hofstede_df %>%
filter(ctr == "USA") %>%
pull(idv)
library("dplyr")
hofstede_df <- read.csv(
"https://geerthofstede.com/wp-content/uploads/2016/08/6-dimensions-for-website-2015-08-16.csv",
sep = ";" #the file isn't separated by commas, but instead semi-colons
)
# What is the individualism score in the US?
us_idv <- hofstede_df %>%
filter(ctr == "USA") %>%
pull(idv)
china_idv <- hofstede_df %>%
filter(ctr == "CHI") %>%
pull(idv)
# average idv?
avg_idv <- hofstede_df %>%
summarize(adv_idv = mean(idv))
# Null values causing problem
avg_idv <- hofstede_df %>%
summarize(adv_idv = mean(idv, na.rm = TRUE))
# Null is a text, so
avg_idv <- hofstede_df %>%
filter(is.numeric(idv))
summarize(adv_idv = mean(idv, na.rm = TRUE))
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
nrow(presidentialElections)
presidentialElections%>% nrow()
filter(presidentialElections, year == 1932)
presidentialElections %>% filter(year == 1932)
presientialElections %>%
filter(year == 1932) %>%
nrow()
presidentialElections %>%
filter(year == 1932) %>%
nrow()
pres_df <- presidentialElections
pres_df %>%
mutate(repVote = 1 - demVote)
pres_df %>%
mutate(repVote = 100 - demVote)
pres_df <- pres_df %>%
mutate(repVote = 100 - demVote)
pres_df %>%
summarize(min_dem_vote = min(demVote))
min_dem_vote <-
pres_df %>%
summarize(min_dem_vote = min(demVote)) %>%
pull(min_dem_vote)
min_dem_vote_rows <-
pres_df %>%
filter(demVote == min_dem_vote)
min_dem_vote_rows <-
pres_df %>%
filter(demVote == min(demVote))
max_dem_vote_rows <-
pres_df %>%
filter(demVote == max(demVote))
np_data <- read.csv("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv")
View(np_data)
max_visits_row <-
np_data %>%
filter(RecreationVisits == max(RecreationVisits))
pull(max_visits_row)
max_visits_row <-
np_data %>%
filter(RecreationVisits == max(RecreationVisits)) %>%
pull(max_visits_row)
max_visits_row <-
np_data %>%
summarize(max_visits_row == max(RecreationVisits)) %>%
pull(max_visits_row)
max_visits_row <-
np_data %>%
summarize(max_visits_row == max(RecreationVisits)) %>%
pull(max_visits_row)
np_data <- read.csv("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv")
max_visits_row <-
np_data %>%
filter(RecreationVisits == max(RecreationVisits))
max_visits <- pull(max_visits_row)
min_visits_row <-
np_data %>%
filter(RecreationVisits == min(RecreationVisits))
min_visits <- pull(min_visits_row)
View(min_visits_row)
View(np_data)
park_state <-
np_data %>%
mutate(park_state = paste0(ParkName, " ", State))
np_data <-
np_data %>%
mutate(park_state = paste0(ParkName, " ", State))
np_data <- read.csv("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv")
np_data <-
np_data %>%
mutate(park_state = paste0(ParkName, " ", State))
max_visits <-
np_data %>%
filter(RecreationVisits == max(RecreationVisits)) %>%
pull(RecreationVisits)
min_visits_row <-
np_data %>%
filter(RecreationVisits == min(RecreationVisits))
min_visits <-
np_data %>%
filter(RecreationVisits == min(RecreationVisits)) %>%
pull(RecreationVisits)
View(np_data)
avg_visits <-
np_data %>%
groupby(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits))
avg_visits <-
np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_visits)
np_data <- read.csv("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv")
View(np_data)
avg_park_visits <-
np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits))
avg_park_visits <-
np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits)) %>%
view(avg_park_visits)
avg_park_visits <-
np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits)) %>%
View(avg_park_visits)
np_data <- read.csv("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv")
avg_park_visits <-
np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_park_visits)
max_avg_visits <-
avg_park_visits %>%
filter(max_average_visits == max(avg_visits))
max_avg_visits <-
avg_park_visits %>%
filter(avg_visits == max(avg_visits))
min_avg_visits <-
avg_park_visits %>%
filter(avg_visits == min(avg_visits))
avg_state_visits <-
np_data %>%
group_by(State) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_state_visits)
View(avg_state_visits)
max_avg_visits <-
avg_state_visits %>%
filter(avg_visits == max(avg_visits))
min_avg_visits <-
avg_state_visits %>%
filter(avg_visits == min(avg_visits))
View(max_avg_visits)
View(min_avg_visits)
avg_park__state_visits <-
np_data %>%
group_by(ParkName, State) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_park__state_visits)
avg_park__state_visits <-
np_data %>%
group_by(ParkName, State) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_park__state_visits)
max_avg_visits <-
avg_park__state_visits %>%
filter(avg_visits == max(avg_visits))
min_avg_visits <-
avg_park__state_visits %>%
filter(avg_visits == min(avg_visits))
View(max_avg_visits)
View(min_avg_visits)
max_avg_visits <-
avg_park__state_visits %>%
filter(avg_visits == max(avg_visits)
distinct_parks <-
distinct_parks <-
np_data %>%
group_by(State) %>%
summarize(distinct_parks = n_distinct(ParkName))
View(distinct_parks)
np_data <- read.csv("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv")
avg_park_visits <-
np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_park_visits)
max_avg_visits <-
avg_park_visits %>%
filter(avg_visits == max(avg_visits))
min_avg_visits <-
avg_park_visits %>%
filter(avg_visits == min(avg_visits))
avg_state_visits <-
np_data %>%
group_by(State) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_state_visits)
max_avg_visits <-
avg_state_visits %>%
filter(avg_visits == max(avg_visits))
min_avg_visits <-
avg_state_visits %>%
filter(avg_visits == min(avg_visits))
avg_park__state_visits <-
np_data %>%
group_by(ParkName, State) %>%
summarize(avg_visits = mean(RecreationVisits))
View(avg_park__state_visits)
distinct_parks <-
np_data %>%
group_by(State) %>%
summarize(distinct_parks = n_distinct(ParkName))
# Sera Lee
# hayunl2@uw.edu
#I worked on this assignment alone using only this quarter's course materials
library("stringr") #loads in the stringr library, all library statements must be at the top of the page!
library("dplyr")
# Note: You may have to run: install.packages("testthat")
library("testthat")
# Note: make sure to set your source-> working directory to current file location
games_df <- read.csv("2013_Video_Games_Dataset.csv") #loads in your dataset DO NOT CHANGE!!
library("stringr") #loads in the stringr library, all library statements must be at the top of the page!
library("dplyr")
# Note: You may have to run: install.packages("testthat")
library("testthat")
# Note: make sure to set your source-> working directory to current file location
games_df <- read.csv("2013_Video_Games_Dataset.csv") #loads in your dataset DO NOT CHANGE!!
# How many games in total are in this dataset? Store this value into a variable called `total_games`
total_games <- nrow(games_df)
# Make a new dataframe called `sequel_games_df` with just the games that are sequels
sequel_games_df <- games_df %>% filter(Sequel == 1)
# How many games are sequels? Store this value into a variable called `total_seq`
total_seq <- nrow(sequel_games_df)
# What percentage of games in the dataset are sequels? Round this number to the nearest whole number/integer
# and store into a variable called `perc_seq`
perc_seq <- round((total_seq/total_games)*100)
# We now want to figure out information about games that were published by AAA studios.
# The AAA studios are:  Activision, Nintendo, Rockstar, Sony, Disney, Electronic Arts, and Microsoft
# Below we provide you with a regular expression (regex) pattern to let you check if a text
# contains any of those studio names:
aaa_studios_pattern <- "Activision|Nintend|Rockstar|Sony|Disney|Electronic Arts|Microsoft"
# Open the games_df dataframe and copy text for one of the publishers, and put save it in
# a variable called `example_publisher_text`
example_publisher_text <- "Electronic Arts, Inc."
# Now try to write code to see if that publisher text has one of those studio names.
# Save the result in a variable called `is_example_publisher_aaa`
is_example_publisher_aaa <- str_detect(example_publisher_text, aaa_studios_pattern)
# Update the games_df to have a new column called `Is_AAA` if a game is produced by an AAA studio
# Hint: Use mutate and re-save the result into `games_df`
games_df <- games_df %>% mutate(Is_AAA = str_detect(Publisher, aaa_studios_pattern))
# How many games in this dataset were published by an AAA studio?
# Store this value into a variable called `total_AAA_games`
# Hint: You can use filter() to help answer this
total_AAA_games <- games_df %>% filter(str_detect(Publisher, aaa_studios_pattern)) %>% nrow()
# What percentage of games where published by an AAA studio? Round this number to the nearest whole number
# and store into a variable called `perc_AAA`. You should use the round function for this task.
perc_AAA <- round((total_AAA_games/total_games)*100)
# Next we want to look at games that were published by a company that also made
# console hardware that many video games are played on (Nintendo, Microsoft, or Sony)?
# Below we provide you with a regular expression (regex) pattern to let you check if a text
# contains any of those studio names:
hardware_studios_pattern <- "Nintend|Sony|Microsoft"
# Update the games_df to have a new column called `Is_Hardware_Studio` if a
# game is produced by one of the hardware studios
games_df <- games_df %>% mutate(Is_Hardware_Studio = str_detect(Publisher, hardware_studios_pattern))
# How many games in this dataset were published by a company that also made the same console hardware
# many of the videogames are played on? i.e how many of these games are published by Nintendo, Microsoft, or Sony?
# Store this value into a variable called `total_hardware_games`
total_hardware_games <- games_df %>% filter(str_detect(Publisher, hardware_studios_pattern)) %>% nrow()
# What percentage of games where published by a company that also makes the console hardware? Round this number up to the nearest whole number
# and store into a variable called `perc_hardware`
perc_hardware <- round((total_hardware_games/total_games)*100)
# What is the highest US sales in millions of dollars reported for any game in the dataset?
# Store this in a variable called `best_seller_sales_millions`.
best_seller_sales_millions <- games_df %>% filter(US.Sales..millions. == max(US.Sales..millions.))
# What was the title of this best selling game?
# Store this value into a variable called `best_seller`.
best_seller <- best_seller_sales_millions %>% select(Title) %>% pull(Title)
# How much money did that game make (in actual dollars not millions of dollars)?
# Store this in a variable called `best_seller_sales`.
best_seller_sales <- best_seller_sales_millions %>% select(US.Sales..millions.) %>% pull(US.Sales..millions.) * 1e6
# Similarly, what is the lowest US sales in millions of dollars reported for any game in the dataset?
# Store this in a variable called `worst_seller_sales_millions`.
worst_seller_sales_millions <- games_df %>% filter(US.Sales..millions. == min(US.Sales..millions.))
# What were the titles of worst selling games in the entire dataset?
# Note: There may be more than one title that tied for selling the worst.
# Store this value into a variable called `worst_seller`.  Make sure you save the values and not a dataframe.
worst_seller <- worst_seller_sales_millions %>% select(Title) %>% pull(Title)
# How much money did that game (or one of those games) make (in actual dollars not millions of dollars)?
# Store this in a variable called `worst_seller_sales`.
worst_seller_sales <- worst_seller_sales_millions %>% select(US.Sales..millions.) %>% pull(US.Sales..millions.) * 1e6
# Fill in the function below called `best_per_yr` that takes in a numeric parameter `year`
# and returns the title of the best selling video games released that year.
# Your function should return a string/character datatype (not a dataframe)!
best_per_yr <- function(year){year_games <- games_df %>% filter(YearReleased)
}
# Use your function to determine the best selling game of 2010.
# Store this in a variable called `top_seller_2010`.
top_seller_2010 <-
# Use your function to determine the best selling game of 2005.
# Store this in a variable called `top_seller_2005`.
# Now let's examine the distribution of game sales across the dataset. To do this,
# get mean and the median sales value (in millions of US dollars).
#Store these two values respectively into  variables named `mean_sales` and `median_sales`.
# Examine values (in US millions) of the mean sales and median sales (and compare with
# the worst sales and best sales).
#
# What does the difference between mean and median tell you? How would you characterize
# a "normal" amount of sales and an "unusual" amount of sales based on this?
#
# Save your answer as text saved into a variable called mean_median_explanation
mean_median_explanation <- "TODO: Answer here"
# How many games in total are in this dataset? Store this value into a variable called `total_games`
total_games <- nrow(games_df)
# Note: make sure to set your source-> working directory to current file location
games_df <- read.csv("2013_Video_Games_Dataset.csv") #loads in your dataset DO NOT CHANGE!!
library("stringr") #loads in the stringr library, all library statements must be at the top of the page!
library("dplyr")
games_df <- read.csv("2013_Video_Games_Dataset.csv")
library("testthat")
games_df <- read.csv("2013_Video_Games_Dataset.csv")
mpg_plot <- ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy))
mpg_plot <- ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy))
library("plotly")
install.packages("plotly")
library("plotly")
mpg_plot <- ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy))
mpg_plot <- ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy))
# facets let me make multiple small graphs based on a coloumn
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy)) +
facet_wrap(~class)
# plotly is for interactive graphs
# we'll sabe our graph and use the function
# ggplotly() mto make it interactive
mpg_plot <- ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy)) +
facet_wrap(~class)
ggplotly(mph_plotly)
ggplotly(mpg_plotly)
ggplotly(mpg_plot)
np_data <- read.csv("https://github.com/melaniewalsh/Neat-Datasets/raw/main/1979-2020-National-Park-Visits-By-State.csv
")
np_data <- read.csv("https://github.com/melaniewalsh/Neat-Datasets/raw/main/1979-2020-National-Park-Visits-By-State.csv")
install.packages("scales")
install.packages("scales")
library("scales")
library("dplyr")
library("ggplot2")
View(np_data)
View(np_data)
# Exercise 1: You're going to compare the recreation visits over time for at least 2 National Parks
# Explore np_data and pick at least 2 NPs that would be interesting to compare
# Filter the data for those 2 or more NPs
my_parks <- np_data %>% filter(ParkName %in% c("Isle Royale NP", "Great Basin")
# Exercise 2: Make a line plot of your 2 or more NPs, and color the lines by the names of the park
# See what the plot looks like before you turn off scientific notation, and then turn off scientific notation by uncommenting and running the line below
# options(scipen = 999)
ggplot(my_parks) + geom_line(aes(x= Year, y = RecreationVisits, color = ParkName))
ggplot(my_parks) + geom_line(aes(x= Year, y = RecreationVisits, color = ParkName))
# Exercise 1: You're going to compare the recreation visits over time for at least 2 National Parks
# Explore np_data and pick at least 2 NPs that would be interesting to compare
# Filter the data for those 2 or more NPs
my_parks <- np_data %>% filter(ParkName %in% c("Isle Royale NP", "Great Basin")
# Exercise 2: Make a line plot of your 2 or more NPs, and color the lines by the names of the park
# See what the plot looks like before you turn off scientific notation, and then turn off scientific notation by uncommenting and running the line below
# options(scipen = 999)
ggplot(my_parks) + geom_line(aes(x= Year, y = RecreationVisits, color = ParkName))
ggplot(my_parks) + geom_line(aes(x= Year, y = RecreationVisits, color = ParkName))
ggplot(my_parks) + geom_line(aes(x= Year, y = RecreationVisits, color = ParkName))
my_parks <- np_data %>% filter(ParkName %in% c("Isle Royale NP", "Great Basin")
# Exercise 1: You're going to compare the recreation visits over time for at least 2 National Parks
# Explore np_data and pick at least 2 NPs that would be interesting to compare
# Filter the data for those 2 or more NPs
my_parks <- np_data %>% filter(ParkName %in% c("Isle Royale NP", "Great Basin") %>% print()
# Exercise 1: You're going to compare the recreation visits over time for at least 2 National Parks
# Explore np_data and pick at least 2 NPs that would be interesting to compare
# Filter the data for those 2 or more NPs
my_parks <- np_data %>% filter(ParkName %in% c("Isle Royale NP", "Great Basin")
np_data <- read.csv("https://github.com/melaniewalsh/Neat-Datasets/raw/main/1979-2020-National-Park-Visits-By-State.csv")
np_data <- read.csv("https://github.com/melaniewalsh/Neat-Datasets/raw/main/1979-2020-National-Park-Visits-By-State.csv")
install.packages("scales")
install.packages("scales")
install.packages("scales")
library("scales")
library("dplyr")
library("ggplot2")
my_parks <- np_data %>% filter(ParkName %in% c("Isle Royale NP", "Great Basin")
# Exercise 1: You're going to compare the recreation visits over time for at least 2 National Parks
# Explore np_data and pick at least 2 NPs that would be interesting to compare
# Filter the data for those 2 or more NPs
my_parks <- np_data %>% filter(ParkName %in% c("Isle Royale NP", "Great Basin"))
my_parks <- np_data %>% filter(ParkName %in% c("Isle Royale NP", "Great Basin"))
ggplot(my_parks) + geom_line(aes(x= Year, y = RecreationVisits, color = ParkName))
View(my_parks)
View(np_data)
my_parks <- np_data %>% filter(ParkName %in% c("Isle Royale NP", "Great Basin NP"))
ggplot(my_parks) + geom_line(aes(x= Year, y = RecreationVisits, color = ParkName))
color_packet <- read.csv("https://r-graph-gallery.com/38-rcolorbrewers-palettes.html")
View(color_packet)
ggplot(my_parks) +geom_line(aes(x = Year, y = RecreationVisits, color = ParkName)) + scale_color_brewer(palette = "Set2") +
labs(title = "'Great' Basin truly greater than Isle 'Royal', x = Year, y = Number of Visits")
ggplot(my_parks) +geom_line(aes(x = Year, y = RecreationVisits, color = ParkName)) + scale_color_brewer(palette = "Set2") +
labs(title = "'Great' Basin truly greater than Isle 'Royal'", x = "Year", y = "Visits")
ggplot(my_parks) +geom_line(aes(x = Year, y = RecreationVisits, color = ParkName)) + scale_color_brewer(palette = "Set2") +
labs(title = "'Great' Basin Truly Greater Than Isle 'Royal'", x = "Year", y = "Visits")
ggplot(my_parks) +geom_line(aes(x = Year, y = RecreationVisits, color = ParkName)) + scale_color_brewer(palette = "Set2") +
labs(title = "'Great' Basin truly greater than Isle 'Royal'", x = "Year", y = "Visits") +
scale_x_continuous(breaks = seq(1980, 2020, 5)) +
scale_y_continuous(labels = label_number_si())
library(dplyr)
library(stringr)
library(testthat)
sleep_df <- read.csv("Sleep_health_and_lifestyle_dataset.csv")
setwd("~/Downloads/INFO201/Final-Project/Info_201_Final_Project")
sleep_df <- read.csv("Sleep_health_and_lifestyle_dataset.csv")
job_df <- read.csv("Occupation Employment and Wage Statistics.csv")
job_df <- read.csv("Occupation Employment and Wage Statistics.csv")
sleep_df <- read.csv("Sleep_health_and_lifestyle_dataset.csv")
job_df <- read.csv("Occupation Employment and Wage Statistics.csv")
job_df <- read.csv("Occupation Employment and Wage Statistics 2.csv")
job_df <- read.csv("Occupation Employment and Wage Statistics.csv")
View(job_df)
combined_df <- sleep_df %>%
left_join(job_df, by = c("Occupation" = "OCC_Title"))
View(job_df)
View(job_df)
jobs_wages_df <- job_df %>% select(OCC_TITLE, H_MEAN, A_MEAN)
View(jobs_wages_df)
job_wages_df <- job_df %>%
select(OCC_TITLE, H_MEAN, A_MEAN)
shiny::runApp('Downloads/shiny-name-app-solution')
install.packages(shiny)
install.packages("markdown")
install.packages("shiny")
install.packages("shiny")
shiny::runApp('Downloads/shiny-name-app-solution')
runApp('Downloads/shiny-name-app')
runApp('Downloads/shiny-name-app')
runApp('Downloads/shiny-name-app')
runApp('Downloads/shiny-name-app')
runApp('Downloads/shiny-name-app')
shiny::runApp('Downloads/INFO201/GitHub/Info_201_Final_Project/final project starter - BH5')
runApp('Downloads/INFO201/GitHub/Info_201_Final_Project/final project starter - BH5')
Occ_physhealth_df <- read.csv("Comprehensive Physical Health and Occupational Statistics Dataset.csv")
setwd("/Users/sera/Downloads/INFO201/GitHub/Info_201_Final_Project")
Occ_physhealth_df <- read.csv("Comprehensive Physical Health and Occupational Statistics Dataset.csv")
runApp('final project starter - BH5')
runApp('final project starter - BH5')
runApp('final project starter - BH5')
runApp('final project starter - BH5')
